{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTb6itvwkYUg+9lbCtOssZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkshayAkshay1/My-1/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8Ar7xplgWK5",
        "outputId": "0ba48854-70ad-424f-dd94-44a1af30437e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (from textstat) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openpyxl\n",
        "import string\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import textstat\n",
        "import re\n",
        "import math\n",
        "from urllib.request import urlopen\n",
        "\n",
        "stopwords_auditor = open('/content/StopWords_Auditor.txt', encoding=\"utf-8\").read()\n",
        "stopwords_Currencies = open('/content/StopWords_Currencies.txt',encoding=\"ISO-8859-1\").read()\n",
        "stopwords_datesandnumbers = open('/content/StopWords_DatesandNumbers.txt',encoding=\"utf-8\").read()\n",
        "StopWords_Generic = open('/content/StopWords_Generic.txt',encoding=\"utf-8\").read()\n",
        "StopWords_GenericLong = open('StopWords_GenericLong.txt',encoding=\"utf-8\").read()\n",
        "StopWords_Geographic = open('StopWords_Geographic.txt',encoding=\"utf-8\").read()\n",
        "StopWords_Names = open('StopWords_Names.txt',encoding=\"utf-8\").read()\n",
        "stopwords = stopwords_auditor+stopwords_Currencies+stopwords_datesandnumbers+StopWords_Generic+StopWords_GenericLong+StopWords_Geographic+StopWords_Names\n",
        "negative_words = open('/content/negative-words.txt', encoding=\"ISO-8859-1\").read()\n",
        "positive_words = open('/content/positive-words.txt', encoding=\"ISO-8859-1\").read()\n",
        "\n",
        "workbook = openpyxl.load_workbook('Input.xlsx')\n",
        "sheet = workbook['Sheet1']\n",
        "Url= []\n",
        "Url_id = []\n",
        "for i in range(2,102):\n",
        "  cell = sheet['B'+ str(i) ]\n",
        "  Url.append(cell.value)\n",
        "  cell = sheet['A'+ str(i)]\n",
        "  Url_id.append(cell.value)\n",
        "\n",
        "positiveScore = []\n",
        "negativeScore = []\n",
        "polarityScore = []\n",
        "subjectivityScore = []\n",
        "averageSentenceLength = []\n",
        "percentageOfComplexWords = []\n",
        "fogIndex = []\n",
        "avgNoOfWordsPerSentence = []\n",
        "complexWordsCount = []\n",
        "wordCount = []\n",
        "syllablePerWord = []\n",
        "personalPronouns = []\n",
        "averageWordLength = []\n",
        "data = []\n",
        "\n",
        "\n",
        "for url in Url:\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "  element = soup.find(\"h1\", class_=\"entry-title\")\n",
        "  if element is not None:\n",
        "    text_title = element.get_text()\n",
        "  element2 = soup.find(\"div\", class_=\"td-post-content\")\n",
        "  if element2 is not None:\n",
        "    text_content=element2.get_text()\n",
        "  final_text = text_title+ ' ' + text_content\n",
        "\n",
        "\n",
        "  lower_case = final_text.lower()\n",
        "  cleaned_text = lower_case.translate(str.maketrans('\\n', ' ', string.punctuation))\n",
        "  tokenized_words = cleaned_text.split()\n",
        "  final_words = []\n",
        "  for word in tokenized_words:\n",
        "      if word not in stopwords:\n",
        "          final_words.append(word)\n",
        "\n",
        "  def count_sentences(text):\n",
        "    sentences = text.split( \".\")\n",
        "    return len(sentences)\n",
        "\n",
        "  def pos_neg_pol_sub_score_avg_sen_len(final_word):\n",
        "    positive_score = 0\n",
        "    negative_score =0\n",
        "    for word in final_word:\n",
        "      if word in positive_words:\n",
        "        positive_score = positive_score +1\n",
        "      elif word in negative_words:\n",
        "        negative_score = negative_score +1\n",
        "    polarity_score = (positive_score-negative_score)/ ((positive_score+negative_score) + 0.000001)\n",
        "    Subjectivity_score =  (positive_score + negative_score)/ ((len(final_word)) + 0.000001)\n",
        "    Average_sentence_length = len(final_words)/count_sentences(final_text)\n",
        "    return positive_score , negative_score , polarity_score , Subjectivity_score, Average_sentence_length\n",
        "\n",
        "\n",
        "  Positive_score,Negative_score,Polarity_score,Subjectivity_Score,Average_sentence_length  = pos_neg_pol_sub_score_avg_sen_len(final_words)\n",
        "\n",
        "  def count_1complex_words(text):\n",
        "      words = text.split()\n",
        "      complex_word_count = 0\n",
        "\n",
        "      for word in words:\n",
        "          syllable_count = textstat.syllable_count(word)\n",
        "\n",
        "          if syllable_count >= 2:\n",
        "              complex_word_count += 1\n",
        "      return complex_word_count\n",
        "  Percentage_of_complex_words = (count_1complex_words(str(final_words))/len(final_words))*100\n",
        "  fog_index = 0.4* (Average_sentence_length+Percentage_of_complex_words)\n",
        "  Average_number_of_words_per_sentence = (len(final_words)/count_sentences(final_text))\n",
        "  def syllable_count(finalwords):\n",
        "      words = finalwords\n",
        "      total = 0\n",
        "      counter = 0\n",
        "      for word in words:\n",
        "          syllable_count = textstat.syllable_count(word)\n",
        "          total= total+syllable_count\n",
        "          counter = counter+1\n",
        "      Average_syllable_count_per_word = total/counter\n",
        "      return Average_syllable_count_per_word\n",
        "  Avg_syllable_count = syllable_count(final_words)\n",
        "  pronounRegex = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
        "  pronouns = pronounRegex.findall(cleaned_text)\n",
        "\n",
        "  def average_word_length(final):\n",
        "    count=0\n",
        "    for word in final:\n",
        "      length = len(word)\n",
        "      count = count + length\n",
        "    average_word_lengths = count/len(final)\n",
        "    return average_word_lengths\n",
        "\n",
        "\n",
        "  Average_number_of_words_per_sentence = (len(final_words)/count_sentences(final_text))\n",
        "  awl = average_word_length(final_words)\n",
        "  count_of_complex_words = count_1complex_words(str(final_words))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  positiveScore.append(round(Positive_score,2))\n",
        "  negativeScore.append(round(Negative_score,2))\n",
        "  polarityScore.append(round(Polarity_score,2))\n",
        "  subjectivityScore.append(round(Subjectivity_Score,2))\n",
        "  averageSentenceLength.append(round(Average_sentence_length,2))\n",
        "  percentageOfComplexWords.append(round(Percentage_of_complex_words,2))\n",
        "  fogIndex.append(round(fog_index,2))\n",
        "  avgNoOfWordsPerSentence.append(round(Average_number_of_words_per_sentence,2))\n",
        "  complexWordsCount.append(round(count_of_complex_words,2))\n",
        "  wordCount.append(round(len(final_words),2))\n",
        "  syllablePerWord.append(round(Avg_syllable_count,2))\n",
        "  personalPronouns.append(round(len(pronouns),2))\n",
        "  averageWordLength.append(round(awl,2))\n",
        "\n",
        "\n",
        "data.append(Url)\n",
        "data.append( Url_id)\n",
        "data.append(positiveScore)\n",
        "data.append(negativeScore)\n",
        "data.append(polarityScore)\n",
        "data.append(subjectivityScore)\n",
        "data.append(averageSentenceLength)\n",
        "data.append(percentageOfComplexWords)\n",
        "data.append(fogIndex)\n",
        "data.append(avgNoOfWordsPerSentence)\n",
        "data.append(complexWordsCount)\n",
        "data.append(wordCount)\n",
        "data.append(syllablePerWord)\n",
        "data.append(personalPronouns)\n",
        "data.append(averageWordLength)\n",
        "\n",
        "\n",
        "pddf = pd.DataFrame(data).T\n",
        "pddf.columns = ['URL', 'URL ID','Positive Score' , 'Negative Score' , 'Polarity Score','Subjectivity Score' , 'Average Sentence Length','Percentage of Complex Words', 'Fog Index','Avg No. Of Words/sentence','Complex Word Count', 'Word Count', 'Syllable Per Word', 'Personal Pronouns','Avg Word Length']\n",
        "pddf.to_excel('output.xlsx', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "KnvOXkpfgzAr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}